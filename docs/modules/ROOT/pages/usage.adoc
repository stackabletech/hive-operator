= Usage

== Requirements
Apache Hive Metastores need a relational database to store their state.
We currently support https://www.postgresql.org/[PostgreSQL] and https://db.apache.org/derby/[Apache Derby] (embedded database, not recommended for production).
Other databases might work if JDBC drivers are available.
Please open an https://github.com/stackabletech/hive-operator/issues[issue] if you require support for another database.

== S3 Support

Hive supports creating tables in S3 compatible object stores.
To use this feature you need to provide connection details for the object store using the xref:home:concepts:s3.adoc[S3Connection] in the top level `clusterConfig`.

An example usage can look like this:

[source,yaml]
----
clusterConfig:
  s3:
    inline:
      host: minio
      port: 9000
      accessStyle: Path
      credentials:
        secretClass: simple-hive-s3-secret-class
----

== Apache HDFS Support

As well as S3, Hive also supports creating tables in HDFS.
You can add the HDFS connection in the top level `clusterConfig` as follows:

[source,yaml]
----
clusterConfig:
  hdfs:
    configMap: my-hdfs-cluster # Name of the HdfsCluster
----

== Monitoring

The managed Hive instances are automatically configured to export Prometheus metrics. See
xref:home:operators:monitoring.adoc[] for more details.

== Configuration & Environment Overrides

The cluster definition also supports overriding configuration properties and environment variables, either per role or per role group, where the more specific override (role group) has precedence over the less specific one (role).

IMPORTANT: Overriding certain properties, which are set by the operator (such as the HTTP port) can interfere with the operator and can lead to problems.

=== Configuration Properties

For a role or role group, at the same level of `config`, you can specify: `configOverrides` for the `hive-site.xml`. For example, if you want to set the `datanucleus.connectionPool.maxPoolSize` for the metastore to 20 adapt the `metastore` section of the cluster resource like so:

[source,yaml]
----
metastore:
  roleGroups:
    default:
      config: [...]
      configOverrides:
        hive-site.xml:
          datanucleus.connectionPool.maxPoolSize: "20"
      replicas: 1
----

Just as for the `config`, it is possible to specify this at role level as well:

[source,yaml]
----
metastore:
  configOverrides:
    hive-site.xml:
      datanucleus.connectionPool.maxPoolSize: "20"
  roleGroups:
    default:
      config: [...]
      replicas: 1
----

All override property values must be strings. The properties will be formatted and escaped correctly into the XML file.

For a full list of configuration options we refer to the Hive https://cwiki.apache.org/confluence/display/hive/configuration+properties[Configuration Reference].

=== Environment Variables

In a similar fashion, environment variables can be (over)written. For example per role group:

[source,yaml]
----
metastore:
  roleGroups:
    default:
      config: {}
      envOverrides:
        MY_ENV_VAR: "MY_VALUE"
      replicas: 1
----

or per role:

[source,yaml]
----
metastore:
  envOverrides:
    MY_ENV_VAR: "MY_VALUE"
  roleGroups:
    default:
      config: {}
      replicas: 1
----

// cliOverrides don't make sense for this operator, so the feature is omitted for now

=== Storage for data volumes

You can mount a volume where the Hive Metastore data is stored by specifying https://kubernetes.io/docs/concepts/storage/persistent-volumes[PersistentVolumeClaims] for each individual role or role group:

[source,yaml]
----
metastore:
  config:
    resources:
      storage:
        data:
          capacity: 2Gi
  roleGroups:
    default:
      config:
        resources:
          storage:
            data:
              capacity: 3Gi
----

In the above example, all Hive Metastores in the default group will store data on a `3Gi` volume. Additional role groups not specifying any resources will inherit the config provided on the role level (`2Gi` volume). This works the same for memory or CPU requests.

By default, in case nothing is configured in the custom resource for a certain role group, each Pod will have a `2Gi` large local volume mount for the data location containing mainly logs.

=== Resource Requests

// The "nightly" version is needed because the "include" directive searches for
// files in the "stable" version by default.
// TODO: remove the "nightly" version after the next platform release (current: 22.09)
include::nightly@home:concepts:stackable_resource_requests.adoc[]

If no resource requests are configured explicitly, the Hive operator uses the following defaults:

[source,yaml]
----
metastore:
  roleGroups:
    default:
      config:
        resources:
          requests:
            cpu: 200m
            memory: 2Gi
          limits:
            cpu: "4"
            memory: 2Gi
          storage:
            data:
              capacity: 2Gi
----

WARNING: The default values are _most likely_ not sufficient to run a proper cluster in production. Please adapt according to your requirements.

For more details regarding Kubernetes CPU limits see: https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/[Assign CPU Resources to Containers and Pods].

== Examples

Please note that the version you need to specify is not only the version of Apache Hive which you want to roll out, but has to be amended with a Stackable version as shown.
This Stackable version is the version of the underlying container image which is used to execute the processes.
For a list of available versions please check our https://repo.stackable.tech/#browse/browse:docker:v2%2Fstackable%2Fhive%2Ftags[image registry].
It should generally be safe to simply use the latest image version that is available.

.Create a single node Apache Hive Metastore cluster using Derby:
[source,yaml]
----
---
apiVersion: hive.stackable.tech/v1alpha1
kind: HiveCluster
metadata:
  name: simple-hive-derby
spec:
  image:
    productVersion: 3.1.3
    stackableVersion: 0.2.0
  clusterConfig:
    database:
      connString: jdbc:derby:;databaseName=/tmp/metastore_db;create=true
      user: APP
      password: mine
      dbType: derby
  metastore:
    roleGroups:
      default:
        replicas: 1
----

WARNING: You should not use the `Derby` database with more than one replica or in production. Derby stores data locally and therefore the data not shared between different metastore Pods and lost after Pod restarts.

To create a single node Apache Hive Metastore (v2.3.9) cluster with derby and S3 access, deploy a minio (or use any available S3 bucket):
[source,bash]
----
helm install minio \
    minio \
    --repo https://charts.bitnami.com/bitnami \
    --set auth.rootUser=minio-access-key \
    --set auth.rootPassword=minio-secret-key
----

In order to upload data to minio we need a port-forward to access the web ui.
[source,bash]
----
kubectl port-forward service/minio 9001
----
Then, connect to localhost:9001 and login with the user `minio-access-key` and password `minio-secret-key`. Create a bucket and upload data.

Deploy the hive cluster:
[source,yaml]
----
---
apiVersion: hive.stackable.tech/v1alpha1
kind: HiveCluster
metadata:
  name: simple-hive-derby
spec:
  image:
    productVersion: 3.1.3
    stackableVersion: 0.2.0
  clusterConfig:
    database:
      connString: jdbc:derby:;databaseName=/stackable/metastore_db;create=true
      user: APP
      password: mine
      dbType: derby
    s3:
      inline:
        host: minio
        port: 9000
        accessStyle: Path
        credentials:
          secretClass: simple-hive-s3-secret-class
  metastore:
    roleGroups:
      default:
        replicas: 1
---
apiVersion: secrets.stackable.tech/v1alpha1
kind: SecretClass
metadata:
  name: simple-hive-s3-secret-class
spec:
  backend:
    k8sSearch:
      searchNamespace:
        pod: {}
---
apiVersion: v1
kind: Secret
metadata:
  name: simple-hive-s3-secret
  labels:
    secrets.stackable.tech/class: simple-hive-s3-secret-class
stringData:
  accessKey: minio-access-key
  secretKey: minio-secret-key
----


To create a single node Apache Hive Metastore using PostgreSQL, deploy a PostgreSQL instance via helm.

[sidebar]
PostgreSQL introduced a new way to encrypt its passwords in version 10.
This is called `scram-sha-256` and has been the default as of PostgreSQL 14.
Unfortunately, Hive up until the latest 3.3.x version ships with JDBC drivers that do https://wiki.postgresql.org/wiki/List_of_drivers[_not_ support] this method.
You might see an error message like this:
`The authentication type 10 is not supported.`
If this is the case please either use an older PostgreSQL version or change its https://www.postgresql.org/docs/current/runtime-config-connection.html#GUC-PASSWORD-ENCRYPTION[`password_encryption`] setting to `md5`.

This installs PostgreSQL in version 10 to work around the issue mentioned above:
[source,bash]
----
helm install hive bitnami/postgresql --version=12.1.5 \
--set postgresqlUsername=hive \
--set postgresqlPassword=hive \
--set postgresqlDatabase=hive
----

.Create Hive Metastore using a PostgreSQL database
[source,yaml]
----
apiVersion: hive.stackable.tech/v1alpha1
kind: HiveCluster
metadata:
  name: simple-hive-postgres
spec:
  image:
    productVersion: 3.1.3
    stackableVersion: 0.2.0
  clusterConfig:
    database:
      connString: jdbc:postgresql://hive-postgresql.default.svc.cluster.local:5432/hive
      user: hive
      password: hive
      dbType: postgres
  metastore:
    roleGroups:
      default:
        replicas: 1
----

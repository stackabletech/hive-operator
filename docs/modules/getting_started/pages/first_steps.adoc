= First steps

After going through the xref:installation.adoc[] section and having installed all the Operators, you will now deploy a Hive metastore cluster and it's dependencies. Afterwards you can <<_verify_that_it_works, verify that it works>> by ingesting example data and subsequently query it.

== Setup

Several requirements should have already been installed in the xref:installation.adoc[Installation guide]:

* xref:commons-operator::index.adoc[Commons Operator]
* xref:secret-operator::index.adoc[Secret Operator]
* xref:hive-operator::index.adoc[Hive Operator]
* A database like PostgreSQL
* (Optional) Minio for S3

=== S3Connection

In order to connect Hive to MinIO we need to create several files (or concat in one file).

A S3Connection to connect to MinIO (_hive-minio-s3-connection.yaml_)

[source,yaml]
----
include::example$code/hive-minio-s3-connection.yaml[]
----

Credentials for the S3Connection to log into MinIO (_hive-minio-credentials.yaml_)

[source,yaml]
----
include::example$code/hive-minio-credentials.yaml[]
----

A SecretClass for the credentials (hive-minio-credentials-secret-class.yaml)

[source,yaml]
----
include::example$code/hive-minio-credentials-secret-class.yaml[]
----

The Apache Hive cluster definition (_hive-postgres-s3.yaml_)

[source,yaml]
----
include::example$code/hive-postgres-s3.yaml[]
----

Once the files are created apply them to the cluster:

[source,bash]
----
include::example$code/getting-started.sh[tag=install-hive]
----

== Verify that it works

First, make sure that all the Pods in the StatefulSets are ready:

[source,bash]
----
kubectl get statefulset
----

The output should show all pods ready:

[source,bash]
----
NAME                                 READY   AGE
hive-postgres-s3-metastore-default   1/1     48s
----

== What's next

Have a look at the xref:ROOT:usage.adoc[] page to find out more about the features of the Operator.
